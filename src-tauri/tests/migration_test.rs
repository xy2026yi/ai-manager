// æ•°æ®è¿ç§»å…¼å®¹æ€§æµ‹è¯•
// éªŒè¯ä»åŸPythoné¡¹ç›®è¿ç§»æ•°æ®çš„å®Œæ•´æ€§å’Œæ ¼å¼ä¸€è‡´æ€§

use chrono::Utc;
use migration_ai_manager_lib::crypto::CryptoService;
use sqlx::{Row, SqlitePool};
use std::collections::HashMap;

// æµ‹è¯•æ•°æ®ç»“æ„
#[derive(Debug)]
struct TestDataRecord {
    table_name: String,
    original_count: i64,
    migrated_count: i64,
    #[allow(dead_code)]
    mismatched_fields: Vec<String>,
    integrity_issues: Vec<String>,
}

// æ•°æ®å®Œæ•´æ€§éªŒè¯å™¨
struct DataIntegrityValidator {
    original_db: SqlitePool,
    migrated_db: SqlitePool,
    #[allow(dead_code)]
    crypto_service: CryptoService,
}

impl DataIntegrityValidator {
    async fn new(
        original_db_path: &str,
        migrated_db_path: &str,
    ) -> Result<Self, Box<dyn std::error::Error>> {
        let original_db = SqlitePool::connect(original_db_path).await?;
        let migrated_db = SqlitePool::connect(migrated_db_path).await?;

        // ä½¿ç”¨ä¸åŸPythoné¡¹ç›®ç›¸åŒçš„å¯†é’¥
        let crypto_service = CryptoService::new("test_migration_key_32_bytes_long!")?;

        Ok(Self { original_db, migrated_db, crypto_service })
    }

    // éªŒè¯è¡¨ç»“æ„ä¸€è‡´æ€§
    async fn verify_table_schemas(
        &self,
    ) -> Result<Vec<TestDataRecord>, Box<dyn std::error::Error>> {
        let tables = vec![
            "claude_providers",
            "codex_providers",
            "agent_guides",
            "mcp_servers",
            "common_configs",
        ];

        let mut results = Vec::new();

        for table in tables {
            let result = self.verify_single_table_schema(table).await?;
            results.push(result);
        }

        Ok(results)
    }

    // éªŒè¯å•ä¸ªè¡¨çš„Schema
    async fn verify_single_table_schema(
        &self,
        table_name: &str,
    ) -> Result<TestDataRecord, Box<dyn std::error::Error>> {
        let original_schema = self.get_table_schema(&self.original_db, table_name).await?;
        let migrated_schema = self.get_table_schema(&self.migrated_db, table_name).await?;

        let mut mismatched_fields = Vec::new();

        // æ¯”è¾ƒå­—æ®µå®šä¹‰
        for (field_name, original_def) in &original_schema {
            match migrated_schema.get(field_name) {
                Some(migrated_def) => {
                    if original_def != migrated_def {
                        mismatched_fields.push(format!(
                            "å­—æ®µ {}: åŸå§‹ '{}' vs è¿ç§»å '{}'",
                            field_name, original_def, migrated_def
                        ));
                    }
                }
                None => {
                    mismatched_fields.push(format!("è¿ç§»åç¼ºå°‘å­—æ®µ: {}", field_name));
                }
            }
        }

        // æ£€æŸ¥æ–°å¢å­—æ®µ
        for field_name in migrated_schema.keys() {
            if !original_schema.contains_key(field_name) {
                mismatched_fields.push(format!("æ–°å¢å­—æ®µ: {}", field_name));
            }
        }

        Ok(TestDataRecord {
            table_name: table_name.to_string(),
            original_count: 0,
            migrated_count: 0,
            mismatched_fields,
            integrity_issues: Vec::new(),
        })
    }

    // è·å–è¡¨ç»“æ„ä¿¡æ¯
    async fn get_table_schema(
        &self,
        pool: &SqlitePool,
        table_name: &str,
    ) -> Result<HashMap<String, String>, Box<dyn std::error::Error>> {
        let query = format!("PRAGMA table_info({})", table_name);

        let rows = sqlx::query(&query).fetch_all(pool).await?;
        let mut schema = HashMap::new();

        for row in rows {
            let name: String = row.get("name");
            let type_name: String = row.get("type");
            let not_null: i32 = row.get("notnull");
            let default_value: Option<String> = row.get("dflt_value");
            let primary_key: i32 = row.get("pk");

            let def = format!(
                "TYPE:{} NOT_NULL:{} DEFAULT:{:?} PK:{}",
                type_name, not_null, default_value, primary_key
            );

            schema.insert(name, def);
        }

        Ok(schema)
    }

    // éªŒè¯æ•°æ®è¡Œæ•°ä¸€è‡´æ€§
    async fn verify_row_counts(&self) -> Result<Vec<TestDataRecord>, Box<dyn std::error::Error>> {
        let tables = vec![
            "claude_providers",
            "codex_providers",
            "agent_guides",
            "mcp_servers",
            "common_configs",
        ];

        let mut results = Vec::new();

        for table in tables {
            let original_count = self.get_row_count(&self.original_db, table).await?;
            let migrated_count = self.get_row_count(&self.migrated_db, table).await?;

            let mut integrity_issues = Vec::new();
            if original_count != migrated_count {
                integrity_issues.push(format!(
                    "è¡Œæ•°ä¸åŒ¹é…: åŸå§‹ {} vs è¿ç§»å {}",
                    original_count, migrated_count
                ));
            }

            results.push(TestDataRecord {
                table_name: table.to_string(),
                original_count,
                migrated_count,
                mismatched_fields: Vec::new(),
                integrity_issues,
            });
        }

        Ok(results)
    }

    // è·å–è¡¨çš„è¡Œæ•°
    async fn get_row_count(
        &self,
        pool: &SqlitePool,
        table_name: &str,
    ) -> Result<i64, Box<dyn std::error::Error>> {
        let query = format!("SELECT COUNT(*) as count FROM {}", table_name);
        let row = sqlx::query(&query).fetch_one(pool).await?;
        Ok(row.get("count"))
    }

    // éªŒè¯æ•°æ®å†…å®¹ä¸€è‡´æ€§ï¼ˆéåŠ å¯†å­—æ®µï¼‰
    async fn verify_unencrypted_data(
        &self,
    ) -> Result<Vec<TestDataRecord>, Box<dyn std::error::Error>> {
        let mut results = Vec::new();

        // éªŒè¯Claudeä¾›åº”å•†ï¼ˆéåŠ å¯†å­—æ®µï¼‰
        let claude_result = self.verify_claude_providers().await?;
        results.push(claude_result);

        // éªŒè¯Codexä¾›åº”å•†ï¼ˆéåŠ å¯†å­—æ®µï¼‰
        let codex_result = self.verify_codex_providers().await?;
        results.push(codex_result);

        // éªŒè¯AgentæŒ‡å¯¼ï¼ˆéåŠ å¯†å­—æ®µï¼‰
        let guide_result = self.verify_agent_guides().await?;
        results.push(guide_result);

        // éªŒè¯MCPæœåŠ¡å™¨ï¼ˆéåŠ å¯†å­—æ®µï¼‰
        let server_result = self.verify_mcp_servers().await?;
        results.push(server_result);

        // éªŒè¯é€šç”¨é…ç½®ï¼ˆéåŠ å¯†å­—æ®µï¼‰
        let config_result = self.verify_common_configs().await?;
        results.push(config_result);

        Ok(results)
    }

    // éªŒè¯Claudeä¾›åº”å•†æ•°æ®
    async fn verify_claude_providers(&self) -> Result<TestDataRecord, Box<dyn std::error::Error>> {
        let original_query = "SELECT id, name, url, max_tokens, temperature, model, enabled, description, timeout, retry_count, created_at, updated_at FROM claude_providers ORDER BY id";
        let migrated_query = "SELECT id, name, url, max_tokens, temperature, model, enabled, description, timeout, retry_count, created_at, updated_at FROM claude_providers ORDER BY id";

        let original_rows = sqlx::query(original_query).fetch_all(&self.original_db).await?;
        let migrated_rows = sqlx::query(migrated_query).fetch_all(&self.migrated_db).await?;

        let mut integrity_issues = Vec::new();

        if original_rows.len() != migrated_rows.len() {
            integrity_issues.push(format!(
                "Claudeä¾›åº”å•†è®°å½•æ•°ä¸åŒ¹é…: åŸå§‹ {} vs è¿ç§»å {}",
                original_rows.len(),
                migrated_rows.len()
            ));
        }

        for (i, (orig_row, mig_row)) in original_rows.iter().zip(migrated_rows.iter()).enumerate() {
            let orig_id: i64 = orig_row.get("id");
            let mig_id: i64 = mig_row.get("id");

            if orig_id != mig_id {
                integrity_issues.push(format!(
                    "è®°å½• {} IDä¸åŒ¹é…: åŸå§‹ {} vs è¿ç§»å {}",
                    i, orig_id, mig_id
                ));
                continue;
            }

            // éªŒè¯éåŠ å¯†å­—æ®µ
            let fields_to_check = vec![
                "name",
                "url",
                "max_tokens",
                "temperature",
                "model",
                "enabled",
                "description",
                "timeout",
                "retry_count",
            ];

            for field in fields_to_check {
                let orig_val: Option<String> = orig_row.try_get(field).unwrap_or(None);
                let mig_val: Option<String> = mig_row.try_get(field).unwrap_or(None);

                if orig_val != mig_val {
                    integrity_issues.push(format!(
                        "è®°å½•ID {} å­—æ®µ '{}' ä¸åŒ¹é…: åŸå§‹ {:?} vs è¿ç§»å {:?}",
                        orig_id, field, orig_val, mig_val
                    ));
                }
            }
        }

        Ok(TestDataRecord {
            table_name: "claude_providers".to_string(),
            original_count: original_rows.len() as i64,
            migrated_count: migrated_rows.len() as i64,
            mismatched_fields: Vec::new(),
            integrity_issues,
        })
    }

    // éªŒè¯Codexä¾›åº”å•†æ•°æ®
    async fn verify_codex_providers(&self) -> Result<TestDataRecord, Box<dyn std::error::Error>> {
        let query = "SELECT id, name, url, type, enabled FROM codex_providers ORDER BY id";

        let original_rows = sqlx::query(query).fetch_all(&self.original_db).await?;
        let migrated_rows = sqlx::query(query).fetch_all(&self.migrated_db).await?;

        let mut integrity_issues = Vec::new();

        if original_rows.len() != migrated_rows.len() {
            integrity_issues.push(format!(
                "Codexä¾›åº”å•†è®°å½•æ•°ä¸åŒ¹é…: åŸå§‹ {} vs è¿ç§»å {}",
                original_rows.len(),
                migrated_rows.len()
            ));
        }

        for (i, (orig_row, mig_row)) in original_rows.iter().zip(migrated_rows.iter()).enumerate() {
            let orig_id: i64 = orig_row.get("id");
            let mig_id: i64 = mig_row.get("id");

            if orig_id != mig_id {
                integrity_issues.push(format!("è®°å½•ID {} ä¸åŒ¹é…", i));
                continue;
            }

            // éªŒè¯å­—æ®µ
            let fields = vec!["name", "url", "type", "enabled"];
            for field in fields {
                let orig_val: Option<String> = orig_row.try_get(field).unwrap_or(None);
                let mig_val: Option<String> = mig_row.try_get(field).unwrap_or(None);

                if orig_val != mig_val {
                    integrity_issues
                        .push(format!("Codexä¾›åº”å•†ID {} å­—æ®µ '{}' ä¸åŒ¹é…", orig_id, field));
                }
            }
        }

        Ok(TestDataRecord {
            table_name: "codex_providers".to_string(),
            original_count: original_rows.len() as i64,
            migrated_count: migrated_rows.len() as i64,
            mismatched_fields: Vec::new(),
            integrity_issues,
        })
    }

    // éªŒè¯AgentæŒ‡å¯¼æ•°æ®
    async fn verify_agent_guides(&self) -> Result<TestDataRecord, Box<dyn std::error::Error>> {
        let query =
            "SELECT id, name, description, created_at, updated_at FROM agent_guides ORDER BY id";

        let original_rows = sqlx::query(query).fetch_all(&self.original_db).await?;
        let migrated_rows = sqlx::query(query).fetch_all(&self.migrated_db).await?;

        let mut integrity_issues = Vec::new();

        if original_rows.len() != migrated_rows.len() {
            integrity_issues.push(format!(
                "AgentæŒ‡å¯¼è®°å½•æ•°ä¸åŒ¹é…: åŸå§‹ {} vs è¿ç§»å {}",
                original_rows.len(),
                migrated_rows.len()
            ));
        }

        for (i, (orig_row, mig_row)) in original_rows.iter().zip(migrated_rows.iter()).enumerate() {
            let orig_id: i64 = orig_row.get("id");
            let mig_id: i64 = mig_row.get("id");

            if orig_id != mig_id {
                integrity_issues.push(format!("AgentæŒ‡å¯¼è®°å½•ID {} ä¸åŒ¹é…", i));
                continue;
            }

            // éªŒè¯å­—æ®µ
            let fields = vec!["name", "description"];
            for field in fields {
                let orig_val: Option<String> = orig_row.try_get(field).unwrap_or(None);
                let mig_val: Option<String> = mig_row.try_get(field).unwrap_or(None);

                if orig_val != mig_val {
                    integrity_issues
                        .push(format!("AgentæŒ‡å¯¼ID {} å­—æ®µ '{}' ä¸åŒ¹é…", orig_id, field));
                }
            }
        }

        Ok(TestDataRecord {
            table_name: "agent_guides".to_string(),
            original_count: original_rows.len() as i64,
            migrated_count: migrated_rows.len() as i64,
            mismatched_fields: Vec::new(),
            integrity_issues,
        })
    }

    // éªŒè¯MCPæœåŠ¡å™¨æ•°æ®
    async fn verify_mcp_servers(&self) -> Result<TestDataRecord, Box<dyn std::error::Error>> {
        let query = "SELECT id, name, url, command, args, enabled, description FROM mcp_servers ORDER BY id";

        let original_rows = sqlx::query(query).fetch_all(&self.original_db).await?;
        let migrated_rows = sqlx::query(query).fetch_all(&self.migrated_db).await?;

        let mut integrity_issues = Vec::new();

        if original_rows.len() != migrated_rows.len() {
            integrity_issues.push(format!(
                "MCPæœåŠ¡å™¨è®°å½•æ•°ä¸åŒ¹é…: åŸå§‹ {} vs è¿ç§»å {}",
                original_rows.len(),
                migrated_rows.len()
            ));
        }

        for (i, (orig_row, mig_row)) in original_rows.iter().zip(migrated_rows.iter()).enumerate() {
            let orig_id: i64 = orig_row.get("id");
            let mig_id: i64 = mig_row.get("id");

            if orig_id != mig_id {
                integrity_issues.push(format!("MCPæœåŠ¡å™¨è®°å½•ID {} ä¸åŒ¹é…", i));
                continue;
            }

            // éªŒè¯å­—æ®µ
            let fields = vec!["name", "url", "command", "args", "enabled", "description"];
            for field in fields {
                let orig_val: Option<String> = orig_row.try_get(field).unwrap_or(None);
                let mig_val: Option<String> = mig_row.try_get(field).unwrap_or(None);

                if orig_val != mig_val {
                    integrity_issues
                        .push(format!("MCPæœåŠ¡å™¨ID {} å­—æ®µ '{}' ä¸åŒ¹é…", orig_id, field));
                }
            }
        }

        Ok(TestDataRecord {
            table_name: "mcp_servers".to_string(),
            original_count: original_rows.len() as i64,
            migrated_count: migrated_rows.len() as i64,
            mismatched_fields: Vec::new(),
            integrity_issues,
        })
    }

    // éªŒè¯é€šç”¨é…ç½®æ•°æ®
    async fn verify_common_configs(&self) -> Result<TestDataRecord, Box<dyn std::error::Error>> {
        let query = "SELECT id, key, value, type, description, created_at, updated_at FROM common_configs ORDER BY id";

        let original_rows = sqlx::query(query).fetch_all(&self.original_db).await?;
        let migrated_rows = sqlx::query(query).fetch_all(&self.migrated_db).await?;

        let mut integrity_issues = Vec::new();

        if original_rows.len() != migrated_rows.len() {
            integrity_issues.push(format!(
                "é€šç”¨é…ç½®è®°å½•æ•°ä¸åŒ¹é…: åŸå§‹ {} vs è¿ç§»å {}",
                original_rows.len(),
                migrated_rows.len()
            ));
        }

        for (i, (orig_row, mig_row)) in original_rows.iter().zip(migrated_rows.iter()).enumerate() {
            let orig_id: i64 = orig_row.get("id");
            let mig_id: i64 = mig_row.get("id");

            if orig_id != mig_id {
                integrity_issues.push(format!("é€šç”¨é…ç½®è®°å½•ID {} ä¸åŒ¹é…", i));
                continue;
            }

            // éªŒè¯å­—æ®µ
            let fields = vec!["key", "value", "type", "description"];
            for field in fields {
                let orig_val: Option<String> = orig_row.try_get(field).unwrap_or(None);
                let mig_val: Option<String> = mig_row.try_get(field).unwrap_or(None);

                if orig_val != mig_val {
                    integrity_issues
                        .push(format!("é€šç”¨é…ç½®ID {} å­—æ®µ '{}' ä¸åŒ¹é…", orig_id, field));
                }
            }
        }

        Ok(TestDataRecord {
            table_name: "common_configs".to_string(),
            original_count: original_rows.len() as i64,
            migrated_count: migrated_rows.len() as i64,
            mismatched_fields: Vec::new(),
            integrity_issues,
        })
    }

    // ç”Ÿæˆæ•°æ®å®Œæ•´æ€§æŠ¥å‘Š
    #[allow(dead_code)]
    fn generate_integrity_report(
        &self,
        schema_results: Vec<TestDataRecord>,
        count_results: Vec<TestDataRecord>,
        data_results: Vec<TestDataRecord>,
    ) -> String {
        let mut report = String::new();

        report.push_str("# æ•°æ®è¿ç§»å®Œæ•´æ€§éªŒè¯æŠ¥å‘Š\n\n");
        report.push_str(&format!(
            "ç”Ÿæˆæ—¶é—´: {}\n\n",
            Utc::now().format("%Y-%m-%d %H:%M:%S UTC")
        ));

        // è¡¨ç»“æ„éªŒè¯ç»“æœ
        report.push_str("## è¡¨ç»“æ„éªŒè¯\n\n");
        for result in &schema_results {
            report.push_str(&format!("### {}\n", result.table_name));
            if result.mismatched_fields.is_empty() {
                report.push_str("âœ… è¡¨ç»“æ„å®Œå…¨ä¸€è‡´\n\n");
            } else {
                report.push_str("âŒ å‘ç°å­—æ®µä¸åŒ¹é…:\n");
                for field in &result.mismatched_fields {
                    report.push_str(&format!("- {}\n", field));
                }
                report.push_str("\n");
            }
        }

        // æ•°æ®è¡Œæ•°éªŒè¯ç»“æœ
        report.push_str("## æ•°æ®è¡Œæ•°éªŒè¯\n\n");
        for result in &count_results {
            report.push_str(&format!("### {}\n", result.table_name));
            if result.integrity_issues.is_empty() {
                report.push_str(&format!(
                    "âœ… è¡Œæ•°ä¸€è‡´: {} -> {}\n\n",
                    result.original_count, result.migrated_count
                ));
            } else {
                report.push_str("âŒ å‘ç°è¡Œæ•°é—®é¢˜:\n");
                for issue in &result.integrity_issues {
                    report.push_str(&format!("- {}\n", issue));
                }
                report.push_str("\n");
            }
        }

        // æ•°æ®å†…å®¹éªŒè¯ç»“æœ
        report.push_str("## æ•°æ®å†…å®¹éªŒè¯\n\n");
        for result in &data_results {
            report.push_str(&format!("### {}\n", result.table_name));
            if result.integrity_issues.is_empty() {
                report.push_str("âœ… æ•°æ®å†…å®¹å®Œå…¨ä¸€è‡´\n\n");
            } else {
                report.push_str("âŒ å‘ç°æ•°æ®ä¸ä¸€è‡´:\n");
                for issue in &result.integrity_issues {
                    report.push_str(&format!("- {}\n", issue));
                }
                report.push_str("\n");
            }
        }

        // æ€»ä½“è¯„ä¼°
        let total_issues = schema_results
            .iter()
            .map(|r| r.mismatched_fields.len())
            .chain(count_results.iter().map(|r| r.integrity_issues.len()))
            .chain(data_results.iter().map(|r| r.integrity_issues.len()))
            .sum::<usize>();

        report.push_str("## æ€»ä½“è¯„ä¼°\n\n");
        if total_issues == 0 {
            report.push_str("ğŸ‰ **è¿ç§»å®Œç¾æˆåŠŸï¼** æ‰€æœ‰æ•°æ®éªŒè¯å‡é€šè¿‡ï¼Œæ— ä»»ä½•é—®é¢˜å‘ç°ã€‚\n");
        } else {
            report.push_str(&format!(
                "âš ï¸ **å‘ç°é—®é¢˜**: å…±å‘ç° {} ä¸ªé—®é¢˜ï¼Œéœ€è¦ä¿®å¤åæ‰èƒ½å®Œæˆè¿ç§»ã€‚\n",
                total_issues
            ));
        }

        report
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use tempfile::tempdir;

    // åˆ›å»ºæµ‹è¯•ç”¨çš„åŸå§‹æ•°æ®åº“
    async fn create_test_original_database(
        db_path: &str,
    ) -> Result<(), Box<dyn std::error::Error>> {
        let pool = SqlitePool::connect(db_path).await?;

        // åˆ›å»ºè¡¨ç»“æ„
        sqlx::query(
            r#"
            CREATE TABLE claude_providers (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                name TEXT NOT NULL,
                url TEXT NOT NULL,
                token TEXT NOT NULL,
                max_tokens INTEGER DEFAULT 4096,
                temperature REAL DEFAULT 0.7,
                model TEXT DEFAULT 'gpt-4',
                enabled INTEGER DEFAULT 1,
                description TEXT,
                timeout INTEGER DEFAULT 30,
                retry_count INTEGER DEFAULT 3,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                updated_at DATETIME DEFAULT CURRENT_TIMESTAMP
            )
            "#,
        )
        .execute(&pool)
        .await?;

        // æ’å…¥æµ‹è¯•æ•°æ®
        sqlx::query(
            r#"
            INSERT INTO claude_providers (name, url, token, enabled, description) 
            VALUES ('Test Provider', 'https://api.test.com', 'encrypted_token_data', 1, 'Test description')
            "#
        ).execute(&pool).await?;

        Ok(())
    }

    #[tokio::test]
    async fn test_data_integrity_validation() {
        // åˆ›å»ºä¸´æ—¶ç›®å½•
        let temp_dir = tempdir().unwrap();
        let original_db_path = temp_dir.path().join("original.db");
        let migrated_db_path = temp_dir.path().join("migrated.db");

        // åˆ›å»ºåŸå§‹æ•°æ®åº“
        create_test_original_database(original_db_path.to_str().unwrap()).await.unwrap();

        // åˆ›å»ºç©ºçš„è¿ç§»æ•°æ®åº“ï¼ˆæ¨¡æ‹Ÿè¿ç§»åçš„çŠ¶æ€ï¼‰
        let migrated_pool = SqlitePool::connect(migrated_db_path.to_str().unwrap()).await.unwrap();

        // è¿è¡Œè¿ç§»è¿‡ç¨‹ï¼ˆè¿™é‡Œç®€åŒ–ä¸ºç›´æ¥å¤åˆ¶è¡¨ç»“æ„å’Œæ•°æ®ï¼‰
        sqlx::query(
            r#"
            CREATE TABLE claude_providers (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                name TEXT NOT NULL,
                url TEXT NOT NULL,
                token TEXT NOT NULL,
                max_tokens INTEGER DEFAULT 4096,
                temperature REAL DEFAULT 0.7,
                model TEXT DEFAULT 'gpt-4',
                enabled INTEGER DEFAULT 1,
                description TEXT,
                timeout INTEGER DEFAULT 30,
                retry_count INTEGER DEFAULT 3,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                updated_at DATETIME DEFAULT CURRENT_TIMESTAMP
            )
            "#,
        )
        .execute(&migrated_pool)
        .await
        .unwrap();

        sqlx::query(
            r#"
            INSERT INTO claude_providers (name, url, token, enabled, description) 
            VALUES ('Test Provider', 'https://api.test.com', 'encrypted_token_data', 1, 'Test description')
            "#
        ).execute(&migrated_pool).await.unwrap();

        // éªŒè¯æ•°æ®å®Œæ•´æ€§
        let validator = DataIntegrityValidator::new(
            original_db_path.to_str().unwrap(),
            migrated_db_path.to_str().unwrap(),
        )
        .await
        .unwrap();

        // éªŒè¯è¡¨ç»“æ„
        let schema_results = validator.verify_table_schemas().await.unwrap();
        assert_eq!(schema_results.len(), 5); // 5ä¸ªä¸»è¦è¡¨

        // éªŒè¯è¡Œæ•°
        let count_results = validator.verify_row_counts().await.unwrap();
        assert_eq!(count_results.len(), 5);

        // éªŒè¯æ•°æ®å†…å®¹
        let data_results = validator.verify_unencrypted_data().await.unwrap();
        assert_eq!(data_results.len(), 5);

        // æ£€æŸ¥Claudeä¾›åº”å•†è¡¨çš„éªŒè¯ç»“æœ
        let claude_result =
            data_results.iter().find(|r| r.table_name == "claude_providers").unwrap();
        assert_eq!(claude_result.original_count, 1);
        assert_eq!(claude_result.migrated_count, 1);
        assert!(claude_result.integrity_issues.is_empty());
    }
}
