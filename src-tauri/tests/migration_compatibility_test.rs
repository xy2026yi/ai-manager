//! æ•°æ®è¿ç§»å…¼å®¹æ€§æµ‹è¯•
//!
//! æµ‹è¯•ä»åŸPythoné¡¹ç›®è¿ç§»æ•°æ®çš„å®Œæ•´æ€§å’ŒåŠ å¯†å…¼å®¹æ€§

use migration_ai_manager_lib::crypto::{python_compatibility, CryptoService};
use migration_ai_manager_lib::database::{DatabaseConfig, DatabaseManager};
use migration_ai_manager_lib::migration_tool::{DataMigrationTool, PythonExportData};
use serde_json;
use sqlx;
use std::fs;
use std::path::Path;
use std::time::Duration;
use tempfile::tempdir;

/// æµ‹è¯•è®¾ç½®ç»“æ„ä½“
struct TestSetup {
    migration_tool: DataMigrationTool,
    db_manager: DatabaseManager,
    temp_dir: tempfile::TempDir,
}

impl TestSetup {
    async fn new() -> Result<Self, Box<dyn std::error::Error>> {
        let temp_dir = tempdir()?;
        let db_path = temp_dir.path().join("test_migration.db");
        let db_url = format!("sqlite:{}", db_path.display());

        let config = DatabaseConfig {
            url: db_url,
            max_connections: 5,
            min_connections: 1,
            connect_timeout: Duration::from_secs(10),
            idle_timeout: Duration::from_secs(60),
            max_lifetime: Duration::from_secs(300),
        };

        let db_manager = DatabaseManager::new(config).await?;
        let migration_tool = DataMigrationTool::new(
            db_manager.clone(),
            "Jw4Ff1BWLnSykdfXDVOuEJCG6m9dyST5B1VhU_qg0fI=",
        )
        .await?;

        Ok(Self { migration_tool, db_manager, temp_dir })
    }
}

#[tokio::test]
async fn test_python_encryption_compatibility() {
    println!("ğŸ” æµ‹è¯•PythonåŠ å¯†å…¼å®¹æ€§...");

    // éªŒè¯Pythonå…¼å®¹æ€§
    let result = python_compatibility::verify_python_compatibility();
    assert!(result.is_ok(), "Pythonå…¼å®¹æ€§æµ‹è¯•åº”è¯¥é€šè¿‡");

    println!("âœ… PythonåŠ å¯†å…¼å®¹æ€§æµ‹è¯•é€šè¿‡");
}

#[tokio::test]
async fn test_full_migration_roundtrip() {
    println!("ğŸ”„ æµ‹è¯•å®Œæ•´è¿ç§»å¾€è¿”...");

    let setup = TestSetup::new().await.expect("æµ‹è¯•è®¾ç½®å¤±è´¥");

    // 1. åŠ è½½æµ‹è¯•æ•°æ®
    let test_data_path = Path::new("tests/data/python_original_sample.json");
    if !test_data_path.exists() {
        // å¦‚æœæµ‹è¯•æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºä¸€ä¸ªç®€åŒ–çš„æµ‹è¯•æ•°æ®
        create_test_sample_file(&setup.temp_dir).await;
    }

    let json_content = fs::read_to_string(test_data_path).unwrap_or_else(|_| {
        // ä½¿ç”¨å†…ç½®æµ‹è¯•æ•°æ®
        serde_json::to_string(&create_sample_json_data()).unwrap()
    });

    // 2. å¯¼å…¥æ•°æ®
    let import_report = setup
        .migration_tool
        .import_from_json(&json_content)
        .await
        .expect("æ•°æ®å¯¼å…¥åº”è¯¥æˆåŠŸ");

    println!("âœ… æ•°æ®å¯¼å…¥å®Œæˆ: {:?}", import_report);
    assert!(import_report.total_migrated > 0, "åº”è¯¥æœ‰æ•°æ®è¢«è¿ç§»");

    // 3. å¯¼å‡ºæ•°æ®
    let exported_data = setup.migration_tool.export_to_json().await.expect("æ•°æ®å¯¼å‡ºåº”è¯¥æˆåŠŸ");

    println!("âœ… æ•°æ®å¯¼å‡ºå®Œæˆ");

    // 4. éªŒè¯æ•°æ®å®Œæ•´æ€§
    let original_data: PythonExportData =
        serde_json::from_str(&json_content).expect("åŸå§‹æ•°æ®è§£æåº”è¯¥æˆåŠŸ");

    verify_data_integrity(&original_data, &exported_data);

    println!("âœ… å®Œæ•´è¿ç§»å¾€è¿”æµ‹è¯•é€šè¿‡");
}

#[tokio::test]
async fn test_encrypted_data_migration() {
    println!("ğŸ”’ æµ‹è¯•åŠ å¯†æ•°æ®è¿ç§»...");

    let setup = TestSetup::new().await.expect("æµ‹è¯•è®¾ç½®å¤±è´¥");

    // åˆ›å»ºåŒ…å«åŠ å¯†tokençš„æµ‹è¯•æ•°æ®
    let mut test_data = create_sample_json_data();

    // æ‰‹åŠ¨åŠ å¯†tokenï¼ˆæ¨¡æ‹ŸPythonåŠ å¯†çš„æ•°æ®ï¼‰
    let crypto_service = CryptoService::new("Jw4Ff1BWLnSykdfXDVOuEJCG6m9dyST5B1VhU_qg0fI=")
        .expect("åŠ å¯†æœåŠ¡åˆ›å»ºåº”è¯¥æˆåŠŸ");

    for provider in &mut test_data.claude_providers {
        provider.token = crypto_service.encrypt(&provider.token).expect("tokenåŠ å¯†åº”è¯¥æˆåŠŸ");
    }

    for provider in &mut test_data.codex_providers {
        provider.token = crypto_service.encrypt(&provider.token).expect("tokenåŠ å¯†åº”è¯¥æˆåŠŸ");
    }

    // å¯¼å…¥åŠ å¯†æ•°æ®
    let json_content = serde_json::to_string(&test_data).expect("åºåˆ—åŒ–åº”è¯¥æˆåŠŸ");

    let import_report = setup
        .migration_tool
        .import_from_json(&json_content)
        .await
        .expect("åŠ å¯†æ•°æ®å¯¼å…¥åº”è¯¥æˆåŠŸ");

    println!("âœ… åŠ å¯†æ•°æ®å¯¼å…¥å®Œæˆ: {:?}", import_report);

    // éªŒè¯æ•°æ®èƒ½æ­£ç¡®è§£å¯†
    let exported_data = setup.migration_tool.export_to_json().await.expect("æ•°æ®å¯¼å‡ºåº”è¯¥æˆåŠŸ");

    // æ£€æŸ¥tokenæ˜¯å¦è¢«æ­£ç¡®è§£å¯†
    for provider in &exported_data.claude_providers {
        assert!(
            !provider.token.starts_with("gAAAA"),
            "tokenåº”è¯¥è¢«è§£å¯†ï¼Œå½“å‰ä»ä¸ºåŠ å¯†çŠ¶æ€: {}",
            &provider.token[..20]
        );
    }

    println!("âœ… åŠ å¯†æ•°æ®è¿ç§»æµ‹è¯•é€šè¿‡");
}

#[tokio::test]
async fn test_migration_error_handling() {
    println!("âš ï¸ æµ‹è¯•è¿ç§»é”™è¯¯å¤„ç†...");

    let setup = TestSetup::new().await.expect("æµ‹è¯•è®¾ç½®å¤±è´¥");

    // æµ‹è¯•æ— æ•ˆJSON
    let invalid_json = "{ invalid json }";
    let result = setup.migration_tool.import_from_json(invalid_json).await;
    assert!(result.is_err(), "æ— æ•ˆJSONåº”è¯¥è¿”å›é”™è¯¯");

    // æµ‹è¯•ä¸æ”¯æŒçš„ç‰ˆæœ¬
    let mut test_data = create_sample_json_data();
    test_data.version = "0.1.0".to_string(); // ä¸æ”¯æŒçš„ç‰ˆæœ¬

    let json_content = serde_json::to_string(&test_data).unwrap();
    let result = setup.migration_tool.import_from_json(&json_content).await;
    assert!(result.is_err(), "ä¸æ”¯æŒçš„ç‰ˆæœ¬åº”è¯¥è¿”å›é”™è¯¯");

    println!("âœ… è¿ç§»é”™è¯¯å¤„ç†æµ‹è¯•é€šè¿‡");
}

#[tokio::test]
async fn test_database_schema_compatibility() {
    println!("ğŸ—„ï¸ æµ‹è¯•æ•°æ®åº“æ¨¡å¼å…¼å®¹æ€§...");

    let setup = TestSetup::new().await.expect("æµ‹è¯•è®¾ç½®å¤±è´¥");

    // å¯¼å…¥æµ‹è¯•æ•°æ®
    let test_data = create_sample_json_data();
    let json_content = serde_json::to_string(&test_data).unwrap();

    let _import_report = setup
        .migration_tool
        .import_from_json(&json_content)
        .await
        .expect("æ•°æ®å¯¼å…¥åº”è¯¥æˆåŠŸ");

    // éªŒè¯æ•°æ®åº“è¡¨ç»“æ„
    let pool = setup.db_manager.pool();

    // æ£€æŸ¥Claudeä¾›åº”å•†è¡¨
    let claude_count: i64 = sqlx::query_scalar("SELECT COUNT(*) FROM claude_providers")
        .fetch_one(pool)
        .await
        .expect("æŸ¥è¯¢Claudeä¾›åº”å•†æ•°é‡åº”è¯¥æˆåŠŸ");

    assert_eq!(
        claude_count,
        test_data.claude_providers.len() as i64,
        "Claudeä¾›åº”å•†æ•°é‡åº”è¯¥åŒ¹é…"
    );

    // æ£€æŸ¥Codexä¾›åº”å•†è¡¨
    let codex_count: i64 = sqlx::query_scalar("SELECT COUNT(*) FROM codex_providers")
        .fetch_one(pool)
        .await
        .expect("æŸ¥è¯¢Codexä¾›åº”å•†æ•°é‡åº”è¯¥æˆåŠŸ");

    assert_eq!(
        codex_count,
        test_data.codex_providers.len() as i64,
        "Codexä¾›åº”å•†æ•°é‡åº”è¯¥åŒ¹é…"
    );

    // æ£€æŸ¥AgentæŒ‡å¯¼æ–‡ä»¶è¡¨
    let agent_count: i64 = sqlx::query_scalar("SELECT COUNT(*) FROM agent_guides")
        .fetch_one(pool)
        .await
        .expect("æŸ¥è¯¢AgentæŒ‡å¯¼æ–‡ä»¶æ•°é‡åº”è¯¥æˆåŠŸ");

    assert_eq!(
        agent_count,
        test_data.agent_guides.len() as i64,
        "AgentæŒ‡å¯¼æ–‡ä»¶æ•°é‡åº”è¯¥åŒ¹é…"
    );

    // æ£€æŸ¥MCPæœåŠ¡å™¨è¡¨
    let mcp_count: i64 = sqlx::query_scalar("SELECT COUNT(*) FROM mcp_servers")
        .fetch_one(pool)
        .await
        .expect("æŸ¥è¯¢MCPæœåŠ¡å™¨æ•°é‡åº”è¯¥æˆåŠŸ");

    assert_eq!(
        mcp_count,
        test_data.mcp_servers.len() as i64,
        "MCPæœåŠ¡å™¨æ•°é‡åº”è¯¥åŒ¹é…"
    );

    // æ£€æŸ¥é€šç”¨é…ç½®è¡¨
    let config_count: i64 = sqlx::query_scalar("SELECT COUNT(*) FROM common_configs")
        .fetch_one(pool)
        .await
        .expect("æŸ¥è¯¢é€šç”¨é…ç½®æ•°é‡åº”è¯¥æˆåŠŸ");

    assert_eq!(
        config_count,
        test_data.common_configs.len() as i64,
        "é€šç”¨é…ç½®æ•°é‡åº”è¯¥åŒ¹é…"
    );

    println!("âœ… æ•°æ®åº“æ¨¡å¼å…¼å®¹æ€§æµ‹è¯•é€šè¿‡");
}

#[tokio::test]
async fn test_data_validation_rules() {
    println!("âœ… æµ‹è¯•æ•°æ®éªŒè¯è§„åˆ™...");

    let setup = TestSetup::new().await.expect("æµ‹è¯•è®¾ç½®å¤±è´¥");

    // æµ‹è¯•ä¾›åº”å•†å”¯ä¸€æ€§è§„åˆ™
    let mut test_data = create_sample_json_data();

    // æ·»åŠ é‡å¤çš„å¯ç”¨ä¾›åº”å•†
    test_data.claude_providers.push(
        migration_ai_manager_lib::migration_tool::PythonClaudeProvider {
            id: None,
            name: "Duplicate Provider".to_string(),
            url: "https://api.anthropic.com".to_string(),
            token: "sk-duplicate-key".to_string(),
            timeout: Some(30000),
            auto_update: Some(1),
            r#type: Some("public_welfare".to_string()),
            enabled: Some(1), // å¤šä¸ªå¯ç”¨ä¾›åº”å•†
            opus_model: Some("claude-3-sonnet-20240229".to_string()),
            sonnet_model: None,
            haiku_model: None,
            created_at: None,
            updated_at: None,
        },
    );

    let json_content = serde_json::to_string(&test_data).unwrap();

    // å¯¼å…¥åº”è¯¥æˆåŠŸï¼Œä½†å¯èƒ½æœ‰è­¦å‘Š
    let import_report = setup
        .migration_tool
        .import_from_json(&json_content)
        .await
        .expect("æ•°æ®å¯¼å…¥åº”è¯¥æˆåŠŸ");

    // æ£€æŸ¥æ˜¯å¦æœ‰å…³äºé‡å¤å¯ç”¨ä¾›åº”å•†çš„è­¦å‘Š
    let has_duplicate_warning = import_report
        .warnings
        .iter()
        .any(|warning| warning.contains("é‡å¤") || warning.contains("duplicate"));

    if has_duplicate_warning {
        println!("âœ… æ£€æµ‹åˆ°é‡å¤ä¾›åº”å•†è­¦å‘Š: {:?}", import_report.warnings);
    } else {
        println!("â„¹ï¸ æœªæ£€æµ‹åˆ°é‡å¤ä¾›åº”å•†è­¦å‘Šï¼ˆå¯èƒ½ç”±ä¸šåŠ¡é€»è¾‘å¤„ç†ï¼‰");
    }

    println!("âœ… æ•°æ®éªŒè¯è§„åˆ™æµ‹è¯•é€šè¿‡");
}

/// åˆ›å»ºç¤ºä¾‹JSONæ•°æ®
fn create_sample_json_data() -> PythonExportData {
    PythonExportData {
        version: "1.0.0".to_string(),
        claude_providers: vec![
            migration_ai_manager_lib::migration_tool::PythonClaudeProvider {
                id: None,
                name: "Test Claude Provider".to_string(),
                url: "https://api.anthropic.com".to_string(),
                token: "sk-ant-test-key-12345".to_string(),
                timeout: Some(30000),
                auto_update: Some(1),
                r#type: Some("public_welfare".to_string()),
                enabled: Some(1),
                opus_model: Some("claude-3-opus-20240229".to_string()),
                sonnet_model: Some("claude-3-sonnet-20240229".to_string()),
                haiku_model: Some("claude-3-haiku-20240307".to_string()),
                created_at: None,
                updated_at: None,
            },
        ],
        codex_providers: vec![
            migration_ai_manager_lib::migration_tool::PythonCodexProvider {
                id: None,
                name: "Test OpenAI Provider".to_string(),
                url: "https://api.openai.com/v1/chat/completions".to_string(),
                token: "sk-test-openai-key-67890".to_string(),
                r#type: Some("official".to_string()),
                enabled: Some(0),
                created_at: None,
                updated_at: None,
            },
        ],
        agent_guides: vec![migration_ai_manager_lib::migration_tool::PythonAgentGuide {
            id: None,
            name: "æµ‹è¯•åŠ©æ‰‹".to_string(),
            r#type: "testing".to_string(),
            text: "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•ç”¨çš„åŠ©æ‰‹æŒ‡å¯¼æ–‡æœ¬ã€‚".to_string(),
            created_at: None,
            updated_at: None,
        }],
        mcp_servers: vec![migration_ai_manager_lib::migration_tool::PythonMcpServer {
            id: None,
            name: "test-filesystem".to_string(),
            r#type: Some("stdio".to_string()),
            timeout: Some(30000),
            command: "npx".to_string(),
            args: vec![
                "@modelcontextprotocol/server-filesystem".to_string(),
                "/tmp".to_string(),
            ],
            env: Some(std::collections::HashMap::from([(
                "NODE_ENV".to_string(),
                "production".to_string(),
            )])),
            created_at: None,
            updated_at: None,
        }],
        common_configs: vec![
            migration_ai_manager_lib::migration_tool::PythonCommonConfig {
                id: None,
                key: "test_config".to_string(),
                value: "test_value".to_string(),
                description: Some("æµ‹è¯•é…ç½®".to_string()),
                category: Some("test".to_string()),
                is_active: Some(1),
                created_at: None,
                updated_at: None,
            },
        ],
    }
}

/// åˆ›å»ºæµ‹è¯•æ ·æœ¬æ–‡ä»¶
async fn create_test_sample_file(temp_dir: &tempfile::TempDir) {
    let sample_file_path = temp_dir.path().join("python_original_sample.json");
    let sample_data = create_sample_json_data();
    let json_content = serde_json::to_string_pretty(&sample_data).unwrap();

    fs::write(sample_file_path, json_content).expect("æµ‹è¯•æ ·æœ¬æ–‡ä»¶å†™å…¥åº”è¯¥æˆåŠŸ");
}

/// éªŒè¯æ•°æ®å®Œæ•´æ€§
fn verify_data_integrity(original: &PythonExportData, exported: &PythonExportData) {
    println!("ğŸ” éªŒè¯æ•°æ®å®Œæ•´æ€§...");

    // éªŒè¯æ•°é‡åŒ¹é…
    assert_eq!(
        original.claude_providers.len(),
        exported.claude_providers.len(),
        "Claudeä¾›åº”å•†æ•°é‡åº”è¯¥åŒ¹é…"
    );
    assert_eq!(
        original.codex_providers.len(),
        exported.codex_providers.len(),
        "Codexä¾›åº”å•†æ•°é‡åº”è¯¥åŒ¹é…"
    );
    assert_eq!(
        original.agent_guides.len(),
        exported.agent_guides.len(),
        "AgentæŒ‡å¯¼æ–‡ä»¶æ•°é‡åº”è¯¥åŒ¹é…"
    );
    assert_eq!(
        original.mcp_servers.len(),
        exported.mcp_servers.len(),
        "MCPæœåŠ¡å™¨æ•°é‡åº”è¯¥åŒ¹é…"
    );
    assert_eq!(
        original.common_configs.len(),
        exported.common_configs.len(),
        "é€šç”¨é…ç½®æ•°é‡åº”è¯¥åŒ¹é…"
    );

    // éªŒè¯å…³é”®æ•°æ®å­—æ®µ
    for (i, orig_provider) in original.claude_providers.iter().enumerate() {
        let exp_provider = &exported.claude_providers[i];
        assert_eq!(orig_provider.name, exp_provider.name, "ä¾›åº”å•†åç§°åº”è¯¥åŒ¹é…");
        assert_eq!(orig_provider.url, exp_provider.url, "ä¾›åº”å•†URLåº”è¯¥åŒ¹é…");
        assert_eq!(
            orig_provider.token, exp_provider.token,
            "ä¾›åº”å•†tokenåº”è¯¥åŒ¹é…"
        );
    }

    for (i, orig_guide) in original.agent_guides.iter().enumerate() {
        let exp_guide = &exported.agent_guides[i];
        assert_eq!(orig_guide.name, exp_guide.name, "æŒ‡å¯¼æ–‡ä»¶åç§°åº”è¯¥åŒ¹é…");
        assert_eq!(orig_guide.text, exp_guide.text, "æŒ‡å¯¼æ–‡ä»¶å†…å®¹åº”è¯¥åŒ¹é…");
    }

    println!("âœ… æ•°æ®å®Œæ•´æ€§éªŒè¯é€šè¿‡");
}
