use sqlx::migrate::MigrateDatabase;
use sqlx::{Pool, Row, Sqlite};
use std::time::Duration;
use thiserror::Error;
use tracing::{debug, error, info, warn};

/// æ•°æ®åº“ç›¸å…³é”™è¯¯ç±»å‹
#[derive(Error, Debug)]
pub enum DatabaseError {
    #[error("æ•°æ®åº“è¿æ¥å¤±è´¥: {0}")]
    Connection(#[from] sqlx::Error),
    #[error("æ•°æ®åº“è¿ç§»å¤±è´¥: {0}")]
    Migration(String),
    #[error("æ•°æ®åº“æŸ¥è¯¢å¤±è´¥: {0}")]
    Query(String),
    #[error("æ•°æ®åº“é…ç½®é”™è¯¯: {0}")]
    Config(String),
}

/// æ•°æ®åº“é…ç½®
#[derive(Debug, Clone)]
pub struct DatabaseConfig {
    pub url: String,
    pub max_connections: u32,
    pub min_connections: u32,
    pub connect_timeout: Duration,
    pub idle_timeout: Duration,
    pub max_lifetime: Duration,
}

impl Default for DatabaseConfig {
    fn default() -> Self {
        Self {
            url: "sqlite:data/ai_manager.db".to_string(),
            max_connections: 10,  // ä¼˜åŒ–è¿æ¥æ± å¤§å°ï¼Œå‡å°‘å†…å­˜å ç”¨
            min_connections: 1,   // æœ€å°è¿æ¥æ•°ï¼Œå‡å°‘èµ„æºæµªè´¹
            connect_timeout: Duration::from_secs(5),  // å¿«é€Ÿè¿æ¥è¶…æ—¶
            idle_timeout: Duration::from_secs(180),   // ä¼˜åŒ–ç©ºé—²è¶…æ—¶
            max_lifetime: Duration::from_secs(600),   // ä¼˜åŒ–è¿æ¥ç”Ÿå‘½å‘¨æœŸ
        }
    }
}

/// æ•°æ®åº“è¿æ¥æ± ç®¡ç†å™¨
#[derive(Clone)]
pub struct DatabaseManager {
    pool: Pool<Sqlite>,
    config: DatabaseConfig,
}

impl DatabaseManager {
    /// åˆ›å»ºæ–°çš„æ•°æ®åº“ç®¡ç†å™¨ï¼ˆä¼˜åŒ–å¯åŠ¨æ—¶é—´ï¼‰
    pub async fn new(config: DatabaseConfig) -> Result<Self, DatabaseError> {
        info!("åˆå§‹åŒ–æ•°æ®åº“è¿æ¥æ± ï¼ŒURL: {}", config.url);

        // ä½¿ç”¨è¿æ¥æ± å»ºç«‹å’Œè¿ç§»å¹¶è¡Œæ‰§è¡Œæ¥ä¼˜åŒ–å¯åŠ¨æ—¶é—´
        let pool_fut = async {
            // æ£€æŸ¥å¹¶åˆ›å»ºæ•°æ®åº“
            if !Sqlite::database_exists(&config.url)
                .await
                .map_err(|e| DatabaseError::Config(format!("æ£€æŸ¥æ•°æ®åº“å­˜åœ¨æ€§å¤±è´¥: {}", e)))?
            {
                warn!("æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°†åˆ›å»ºæ–°æ•°æ®åº“");
                Sqlite::create_database(&config.url)
                    .await
                    .map_err(|e| DatabaseError::Config(format!("åˆ›å»ºæ•°æ®åº“å¤±è´¥: {}", e)))?;
                info!("âœ… æ•°æ®åº“åˆ›å»ºæˆåŠŸ");
            }

            // é…ç½®æ€§èƒ½ä¼˜åŒ–çš„è¿æ¥æ± é€‰é¡¹
            let pool_options = sqlx::sqlite::SqlitePoolOptions::new()
                .max_connections(config.max_connections)
                .min_connections(config.min_connections)
                .idle_timeout(config.idle_timeout)
                .max_lifetime(config.max_lifetime)
                .acquire_timeout(Duration::from_secs(10)) // å‡å°‘è·å–è¿æ¥è¶…æ—¶
                .test_before_acquire(true) // è¿æ¥å‰æµ‹è¯•ï¼Œé¿å…ä½¿ç”¨æŸåçš„è¿æ¥
                // å¯ç”¨è¿æ¥æ± çš„æ€§èƒ½ä¼˜åŒ–è®¾ç½®
                .after_connect(|conn, _meta| {
                    Box::pin(async move {
                        // SQLiteæ€§èƒ½ä¼˜åŒ–è®¾ç½®
                        sqlx::query("PRAGMA journal_mode = WAL")
                            .execute(&mut *conn)
                            .await?;
                        sqlx::query("PRAGMA synchronous = NORMAL") // å¹³è¡¡æ€§èƒ½å’Œå®‰å…¨æ€§
                            .execute(&mut *conn)
                            .await?;
                        sqlx::query("PRAGMA cache_size = -64000") // 64MBç¼“å­˜
                            .execute(&mut *conn)
                            .await?;
                        sqlx::query("PRAGMA temp_store = MEMORY") // ä¸´æ—¶è¡¨å­˜å‚¨åœ¨å†…å­˜
                            .execute(&mut *conn)
                            .await?;
                        sqlx::query("PRAGMA mmap_size = 268435456") // 256MBå†…å­˜æ˜ å°„
                            .execute(&mut *conn)
                            .await?;
                        sqlx::query("PRAGMA optimize") // è‡ªåŠ¨ä¼˜åŒ–æŸ¥è¯¢è®¡åˆ’
                            .execute(&mut *conn)
                            .await?;
                        Ok(())
                    })
                });

            // åˆ›å»ºè¿æ¥æ± 
            pool_options
                .connect(&config.url)
                .await
                .map_err(|e| DatabaseError::Connection(e))
        };

        // ç­‰å¾…è¿æ¥æ± å»ºç«‹
        let pool = pool_fut.await?;

        info!("âœ… æ•°æ®åº“è¿æ¥æ± åˆ›å»ºæˆåŠŸ");

        let manager = Self { pool, config };

        // å¼‚æ­¥è¿è¡Œæ•°æ®åº“è¿ç§»å’Œæ€§èƒ½ä¼˜åŒ–ï¼Œä¸é˜»å¡è¿”å›
        let manager_clone = manager.clone();
        tokio::spawn(async move {
            // è¿è¡Œæ•°æ®åº“è¿ç§»
            if let Err(e) = manager_clone.run_migrations().await {
                error!("æ•°æ®åº“è¿ç§»å¤±è´¥: {}", e);
            }

            // åˆ›å»ºæ€§èƒ½ç´¢å¼•
            let query_builder = QueryBuilder::new(manager_clone.pool());
            if let Err(e) = query_builder.create_performance_indexes().await {
                warn!("æ€§èƒ½ç´¢å¼•åˆ›å»ºå¤±è´¥: {}", e);
            }

            // è¿æ¥æ± é¢„çƒ­ï¼šåˆ›å»ºæœ€å°è¿æ¥æ•°ï¼Œä¼˜åŒ–é¦–æ¬¡æŸ¥è¯¢æ€§èƒ½
            if let Err(e) = manager_clone.warmup_connection_pool().await {
                warn!("è¿æ¥æ± é¢„çƒ­å¤±è´¥: {}", e);
            }

            info!("âœ… æ•°æ®åº“åˆå§‹åŒ–å’Œæ€§èƒ½ä¼˜åŒ–å®Œæˆ");
        });

        Ok(manager)
    }

    /// ä½¿ç”¨é»˜è®¤é…ç½®åˆ›å»ºæ•°æ®åº“ç®¡ç†å™¨
    pub async fn new_default() -> Result<Self, DatabaseError> {
        Self::new(DatabaseConfig::default()).await
    }

    /// è¿è¡Œæ•°æ®åº“è¿ç§»
    async fn run_migrations(&self) -> Result<(), DatabaseError> {
        info!("å¼€å§‹è¿è¡Œæ•°æ®åº“è¿ç§»");

        sqlx::migrate!("./migrations")
            .run(&self.pool)
            .await
            .map_err(|e| DatabaseError::Migration(e.to_string()))?;

        info!("âœ… æ•°æ®åº“è¿ç§»å®Œæˆ");
        Ok(())
    }

    /// è·å–è¿æ¥æ± å¼•ç”¨
    pub fn pool(&self) -> &Pool<Sqlite> {
        &self.pool
    }

    /// æµ‹è¯•æ•°æ®åº“è¿æ¥
    pub async fn test_connection(&self) -> Result<(), DatabaseError> {
        debug!("æµ‹è¯•æ•°æ®åº“è¿æ¥");

        let result = sqlx::query("SELECT 1 as test").fetch_one(&self.pool).await;

        match result {
            Ok(row) => {
                let test_val: i64 = row.get("test");
                if test_val == 1 {
                    info!("âœ… æ•°æ®åº“è¿æ¥æµ‹è¯•æˆåŠŸ");
                    Ok(())
                } else {
                    Err(DatabaseError::Query("æµ‹è¯•æŸ¥è¯¢è¿”å›æ„å¤–ç»“æœ".to_string()))
                }
            }
            Err(e) => {
                error!("âŒ æ•°æ®åº“è¿æ¥æµ‹è¯•å¤±è´¥: {}", e);
                Err(DatabaseError::Connection(e))
            }
        }
    }

    /// è·å–è¿æ¥æ± çŠ¶æ€ä¿¡æ¯
    pub async fn pool_status(&self) -> PoolStatus {
        PoolStatus { size: self.pool.size(), idle: self.pool.num_idle() as u32 }
    }

    /// å¥åº·æ£€æŸ¥
    pub async fn health_check(&self) -> Result<(), sqlx::Error> {
        self.pool.acquire().await?;
        Ok(())
    }

    /// è¿æ¥æ± é¢„çƒ­ - åˆ›å»ºæœ€å°è¿æ¥æ•°ï¼Œä¼˜åŒ–é¦–æ¬¡æŸ¥è¯¢æ€§èƒ½
    pub async fn warmup_connection_pool(&self) -> Result<(), DatabaseError> {
        debug!("å¼€å§‹è¿æ¥æ± é¢„çƒ­");

        // å¹¶è¡Œåˆ›å»ºå¤šä¸ªè¿æ¥ä»¥è¾¾åˆ°æœ€å°è¿æ¥æ•°
        let pool = &self.pool;
        let warmup_tasks: Vec<_> = (0..self.config.min_connections)
            .map(|_| async {
                // ç›´æ¥åœ¨æ± ä¸Šæ‰§è¡ŒæŸ¥è¯¢æ¥åˆ›å»ºå’Œæµ‹è¯•è¿æ¥
                sqlx::query("SELECT 1")
                    .fetch_one(pool)
                    .await
                    .map_err(|e| DatabaseError::Connection(e))?;

                Ok::<(), DatabaseError>(())
            })
            .collect();

        // ç­‰å¾…æ‰€æœ‰é¢„çƒ­ä»»åŠ¡å®Œæˆ
        let results = futures::future::join_all(warmup_tasks).await;

        let mut errors = 0;
        for result in results {
            if let Err(e) = result {
                warn!("è¿æ¥æ± é¢„çƒ­è¿æ¥å¤±è´¥: {}", e);
                errors += 1;
            }
        }

        if errors == 0 {
            info!("âœ… è¿æ¥æ± é¢„çƒ­å®Œæˆï¼Œ{} ä¸ªè¿æ¥å°±ç»ª", self.config.min_connections);
        } else {
            warn!("âš ï¸ è¿æ¥æ± é¢„çƒ­éƒ¨åˆ†å¤±è´¥ï¼Œ{}/{} ä¸ªè¿æ¥å¤±è´¥", errors, self.config.min_connections);
        }

        Ok(())
    }

    /// å…³é—­è¿æ¥æ± 
    pub async fn close(self) {
        info!("å…³é—­æ•°æ®åº“è¿æ¥æ± ");
        self.pool.close().await;
        info!("âœ… æ•°æ®åº“è¿æ¥æ± å·²å…³é—­");
    }
}

/// è¿æ¥æ± çŠ¶æ€ä¿¡æ¯
#[derive(Debug)]
pub struct PoolStatus {
    pub size: u32,
    pub idle: u32,
}

impl std::fmt::Display for PoolStatus {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        write!(
            f,
            "è¿æ¥æ± çŠ¶æ€: æ€»è¿æ¥æ•°={}, ç©ºé—²è¿æ¥æ•°={}",
            self.size, self.idle
        )
    }
}

/// è¡¨æ€§èƒ½ç»Ÿè®¡ä¿¡æ¯
#[derive(Debug, serde::Serialize)]
pub struct TablePerformanceStats {
    pub name: String,
    pub record_count: i64,
    pub estimated_size_bytes: i64,
    pub index_count: i64,
}

impl std::fmt::Display for TablePerformanceStats {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        write!(
            f,
            "è¡¨ '{}': {} æ¡è®°å½•, ~{}KB, {} ä¸ªç´¢å¼•",
            self.name,
            self.record_count,
            self.estimated_size_bytes / 1024,
            self.index_count
        )
    }
}

/// æ•°æ®åº“æŸ¥è¯¢æ„å»ºå™¨
pub struct QueryBuilder<'a> {
    pool: &'a Pool<Sqlite>,
}

impl<'a> QueryBuilder<'a> {
    pub fn new(pool: &'a Pool<Sqlite>) -> Self {
        Self { pool }
    }

    /// æ‰§è¡ŒåŸå§‹SQLæŸ¥è¯¢ï¼ˆç®€å•ç‰ˆæœ¬ï¼Œåªæ”¯æŒå­—ç¬¦ä¸²å‚æ•°ï¼‰
    pub async fn execute_raw(
        &self,
        query: &str,
        params: &[&str],
    ) -> Result<sqlx::sqlite::SqliteQueryResult, DatabaseError> {
        let mut query_builder = sqlx::query(query);

        for param in params {
            query_builder = query_builder.bind(param);
        }

        query_builder
            .execute(self.pool)
            .await
            .map_err(|e| DatabaseError::Query(e.to_string()))
    }

    /// æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
    pub async fn table_exists(&self, table_name: &str) -> Result<bool, DatabaseError> {
        let result = sqlx::query("SELECT name FROM sqlite_master WHERE type='table' AND name=?")
            .bind(table_name)
            .fetch_optional(self.pool)
            .await
            .map_err(|e| DatabaseError::Query(e.to_string()))?;

        Ok(result.is_some())
    }

    /// è·å–è¡¨çš„è®°å½•æ•°ï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼Œä½¿ç”¨é¢„ç¼–è¯‘è¯­å¥ï¼‰
    pub async fn count_records(&self, table_name: &str) -> Result<i64, DatabaseError> {
        let query = format!("SELECT COUNT(*) as count FROM {}", table_name);
        let result = sqlx::query(&query)
            .fetch_one(self.pool)
            .await
            .map_err(|e| DatabaseError::Query(e.to_string()))?;

        let count: i64 = result.get("count");
        Ok(count)
    }

    /// æ‰§è¡Œä¼˜åŒ–çš„æ‰¹é‡æ’å…¥ï¼ˆæ€§èƒ½ä¼˜åŒ–ç‰ˆæœ¬ï¼‰
    pub async fn batch_insert(
        &self,
        table: &str,
        columns: &[&str],
        values: Vec<Vec<String>>,
    ) -> Result<u64, DatabaseError> {
        if values.is_empty() {
            return Ok(0);
        }

        // éªŒè¯æ•°æ®ä¸€è‡´æ€§
        let expected_cols = columns.len();
        for (i, row) in values.iter().enumerate() {
            if row.len() != expected_cols {
                return Err(DatabaseError::Query(
                    format!("ç¬¬{}è¡Œæ•°æ®é•¿åº¦({})ä¸åˆ—æ•°({})ä¸åŒ¹é…", i + 1, row.len(), expected_cols)
                ));
            }
        }

        // ä½¿ç”¨äº‹åŠ¡æé«˜æ‰¹é‡æ’å…¥æ€§èƒ½
        let mut tx = self.pool.begin()
            .await
            .map_err(|e| DatabaseError::Query(format!("å¼€å§‹äº‹åŠ¡å¤±è´¥: {}", e)))?;

        let mut total_changes = 0;

        // æ‰¹é‡å¤§å°ä¼˜åŒ–ï¼šæ¯æ‰¹å¤„ç†1000è¡Œä»¥é¿å…å†…å­˜æº¢å‡º
        const BATCH_SIZE: usize = 1000;

        for chunk in values.chunks(BATCH_SIZE) {
            // é¢„ç¼–è¯‘æ’å…¥è¯­å¥ä»¥æé«˜æ€§èƒ½
            let placeholders: Vec<String> = (0..expected_cols).map(|_| "?".to_string()).collect();
            let query_str = format!(
                "INSERT INTO {} ({}) VALUES ({})",
                table,
                columns.join(","),
                placeholders.join(",")
            );

            // åœ¨äº‹åŠ¡å†…æ‰§è¡ŒæŸ¥è¯¢ï¼ˆä¿®å¤å…³é”®é—®é¢˜ï¼‰
            for row in chunk {
                let query = row.iter().fold(
                    sqlx::query(&query_str),
                    |q, value| q.bind(value)
                );

                let result = query.execute(&mut *tx).await
                    .map_err(|e| DatabaseError::Query(format!("æ‰¹é‡æ’å…¥å¤±è´¥: {}", e)))?;

                total_changes += result.rows_affected();
            }

            // æ¯æ‰¹åçŸ­æš‚é‡Šæ”¾CPUï¼Œé¿å…é˜»å¡UI
            tokio::task::yield_now().await;
        }

        // æäº¤äº‹åŠ¡
        tx.commit()
            .await
            .map_err(|e| DatabaseError::Query(format!("æäº¤äº‹åŠ¡å¤±è´¥: {}", e)))?;

        Ok(total_changes)
    }

    /// åˆ›å»ºæ€§èƒ½ä¼˜åŒ–ç´¢å¼•
    pub async fn create_performance_indexes(&self) -> Result<(), DatabaseError> {
        tracing::info!("åˆ›å»ºæ€§èƒ½ä¼˜åŒ–ç´¢å¼•");

        let indexes = vec![
            ("idx_claude_providers_enabled", "CREATE INDEX IF NOT EXISTS idx_claude_providers_enabled ON claude_providers(enabled)"),
            ("idx_claude_providers_type", "CREATE INDEX IF NOT EXISTS idx_claude_providers_type ON claude_providers(type)"),
            ("idx_claude_providers_name", "CREATE INDEX IF NOT EXISTS idx_claude_providers_name ON claude_providers(name)"),
            ("idx_claude_providers_created", "CREATE INDEX IF NOT EXISTS idx_claude_providers_created ON claude_providers(created_at)"),
            
            ("idx_codex_providers_enabled", "CREATE INDEX IF NOT EXISTS idx_codex_providers_enabled ON codex_providers(enabled)"),
            ("idx_codex_providers_type", "CREATE INDEX IF NOT EXISTS idx_codex_providers_type ON codex_providers(type)"),
            
            ("idx_agent_guides_type", "CREATE INDEX IF NOT EXISTS idx_agent_guides_type ON agent_guides(type)"),
            ("idx_agent_guides_name", "CREATE INDEX IF NOT EXISTS idx_agent_guides_name ON agent_guides(name)"),
            
            ("idx_mcp_servers_type", "CREATE INDEX IF NOT EXISTS idx_mcp_servers_type ON mcp_servers(type)"),
            ("idx_mcp_servers_command", "CREATE INDEX IF NOT EXISTS idx_mcp_servers_command ON mcp_servers(command)"),
            
            ("idx_common_configs_key", "CREATE INDEX IF NOT EXISTS idx_common_configs_key ON common_configs(key)"),
            ("idx_common_configs_category", "CREATE INDEX IF NOT EXISTS idx_common_configs_category ON common_configs(category)"),
            ("idx_common_configs_active", "CREATE INDEX IF NOT EXISTS idx_common_configs_active ON common_configs(is_active)"),
        ];

        for (name, query) in indexes {
            sqlx::query(query)
                .execute(self.pool)
                .await
                .map_err(|e| DatabaseError::Query(format!("åˆ›å»ºç´¢å¼• {} å¤±è´¥: {}", name, e)))?;
        }

        tracing::info!("âœ… æ€§èƒ½ä¼˜åŒ–ç´¢å¼•åˆ›å»ºå®Œæˆ");
        Ok(())
    }

    /// åˆ†æè¡¨æ€§èƒ½ç»Ÿè®¡
    pub async fn analyze_table_performance(&self, table_name: &str) -> Result<TablePerformanceStats, DatabaseError> {
        // è·å–è®°å½•æ•°
        let count = self.count_records(table_name).await?;

        // è·å–è¡¨å¤§å°ä¿¡æ¯ï¼ˆSQLiteç‰¹å®šï¼‰
        let size_query = "SELECT COUNT(*) * 1024 as estimated_size FROM sqlite_master WHERE type='table' AND name=?";
        let size_result = sqlx::query(size_query)
            .bind(table_name)
            .fetch_one(self.pool)
            .await
            .map_err(|e| DatabaseError::Query(e.to_string()))?;

        let estimated_size: i64 = size_result.get("estimated_size");

        // è·å–ç´¢å¼•ä¿¡æ¯
        let index_query = "SELECT COUNT(*) as index_count FROM sqlite_master WHERE type='index' AND tbl_name=?";
        let index_result = sqlx::query(index_query)
            .bind(table_name)
            .fetch_one(self.pool)
            .await
            .map_err(|e| DatabaseError::Query(e.to_string()))?;

        let index_count: i64 = index_result.get("index_count");

        Ok(TablePerformanceStats {
            name: table_name.to_string(),
            record_count: count,
            estimated_size_bytes: estimated_size,
            index_count,
        })
    }

    /// æ¸…ç†å’Œä¼˜åŒ–æ•°æ®åº“
    pub async fn vacuum_and_analyze(&self) -> Result<(), DatabaseError> {
        tracing::info!("å¼€å§‹æ•°æ®åº“æ¸…ç†å’Œä¼˜åŒ–");

        // VACUUM é‡æ–°ç»„ç»‡æ•°æ®åº“æ–‡ä»¶ï¼Œå‡å°‘ç¢ç‰‡
        sqlx::query("VACUUM")
            .execute(self.pool)
            .await
            .map_err(|e| DatabaseError::Query(format!("VACUUM å¤±è´¥: {}", e)))?;

        // ANALYZE æ›´æ–°æŸ¥è¯¢è®¡åˆ’å™¨ç»Ÿè®¡ä¿¡æ¯
        sqlx::query("ANALYZE")
            .execute(self.pool)
            .await
            .map_err(|e| DatabaseError::Query(format!("ANALYZE å¤±è´¥: {}", e)))?;

        tracing::info!("âœ… æ•°æ®åº“æ¸…ç†å’Œä¼˜åŒ–å®Œæˆ");
        Ok(())
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use tempfile::NamedTempFile;

    async fn create_test_database() -> DatabaseManager {
        let temp_file = NamedTempFile::new().unwrap();
        let db_url = temp_file.path().to_str().unwrap().to_string();

        // ä¿æŒæ–‡ä»¶ä¸è¢«åˆ é™¤ï¼Œé€šè¿‡å¤åˆ¶åˆ°æ–°è·¯å¾„
        let persistent_db = format!("{}_test.db", db_url);
        std::fs::copy(&db_url, &persistent_db).unwrap();

        let config = DatabaseConfig {
            url: persistent_db,
            max_connections: 5,
            min_connections: 1,
            connect_timeout: Duration::from_secs(10),
            idle_timeout: Duration::from_secs(60),
            max_lifetime: Duration::from_secs(300),
        };

        DatabaseManager::new(config).await.unwrap()
    }

    #[tokio::test]
    async fn test_database_creation() {
        let db_manager = create_test_database().await;

        // æµ‹è¯•è¿æ¥
        match db_manager.test_connection().await {
            Ok(_) => println!("âœ… æ•°æ®åº“è¿æ¥æµ‹è¯•æˆåŠŸ"),
            Err(e) => {
                println!("âŒ æ•°æ®åº“è¿æ¥æµ‹è¯•å¤±è´¥: {:?}", e);
                panic!("æ•°æ®åº“è¿æ¥æµ‹è¯•å¤±è´¥");
            }
        }

        // æµ‹è¯•è¡¨å­˜åœ¨æ£€æŸ¥
        let query_builder = QueryBuilder::new(db_manager.pool());
        assert!(query_builder.table_exists("claude_providers").await.unwrap());
        assert!(query_builder.table_exists("codex_providers").await.unwrap());
        assert!(query_builder.table_exists("agent_guides").await.unwrap());
        assert!(query_builder.table_exists("mcp_servers").await.unwrap());
        assert!(query_builder.table_exists("common_configs").await.unwrap());

        // æµ‹è¯•è®°å½•è®¡æ•°
        let count = query_builder.count_records("claude_providers").await.unwrap();
        assert_eq!(count, 0); // åº”è¯¥æ˜¯ç©ºè¡¨
    }

    #[tokio::test]
    async fn test_pool_status() {
        let db_manager = create_test_database().await;
        let status = db_manager.pool_status().await;
        println!("ğŸ“Š {}", status);

        assert!(status.size <= 5); // ä¸åº”è¶…è¿‡æœ€å¤§è¿æ¥æ•°
    }

    #[tokio::test]
    async fn test_query_builder() {
        let db_manager = create_test_database().await;
        let query_builder = QueryBuilder::new(db_manager.pool());

        // æµ‹è¯•æ’å…¥å’ŒæŸ¥è¯¢
        let result = query_builder
            .execute_raw(
                "INSERT INTO common_configs (key, value, category) VALUES (?, ?, ?)",
                &["test_key", "test_value", "test"],
            )
            .await;

        assert!(result.is_ok());

        let count = query_builder.count_records("common_configs").await.unwrap();
        assert_eq!(count, 1);
    }
}
