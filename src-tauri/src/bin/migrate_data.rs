//! ä¸€æ¬¡æ€§æ•°æ®è¿ç§»å·¥å…·
//! ä»åŸPythonç‰ˆæœ¬çš„AI Manageræ•°æ®åº“è¿ç§»æ•°æ®åˆ°æ–°çš„Rust/Tauriç‰ˆæœ¬

use migration_ai_manager_lib::{CryptoService, DatabaseManager};
use serde::{Deserialize, Serialize};
use sqlx::Row;
use std::env;
use std::path::Path;
use tracing::{error, info, warn};

#[derive(Debug, Serialize, Deserialize)]
struct MigratedData {
    claude_providers: usize,
    codex_providers: usize,
    agent_guides: usize,
    mcp_servers: usize,
    common_configs: usize,
    errors: Vec<String>,
}

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    // åˆå§‹åŒ–æ—¥å¿—
    tracing_subscriber::fmt().with_max_level(tracing::Level::INFO).init();

    info!("ğŸš€ å¼€å§‹AI Manageræ•°æ®è¿ç§»...");

    // è·å–å‘½ä»¤è¡Œå‚æ•°
    let args: Vec<String> = env::args().collect();

    // æ£€æŸ¥å¸®åŠ©å‚æ•°
    if args.len() < 2 || args.iter().any(|arg| arg == "--help" || arg == "-h") {
        print_usage();
        return Ok(());
    }

    let mut source_db_path: String = String::new();
    let mut target_db_path: String = "data/ai_manager.db".to_string();
    let mut dry_run = false;

    let mut i = 1;
    while i < args.len() {
        match args[i].as_str() {
            "--dry-run" => dry_run = true,
            arg if arg.starts_with('-') => {
                error!("æœªçŸ¥å‚æ•°: {}", arg);
                return Ok(());
            }
            _ => {
                if source_db_path.is_empty() {
                    source_db_path = args[i].clone();
                } else if !args[i].starts_with('-') {
                    target_db_path = args[i].clone();
                }
            }
        }
        i += 1;
    }

    if source_db_path.is_empty() {
        print_usage();
        return Ok(());
    }

    info!("æºæ•°æ®åº“: {}", source_db_path);
    info!("ç›®æ ‡æ•°æ®åº“: {}", target_db_path);
    if dry_run {
        info!("æ¨¡å¼: é¢„è§ˆæ¨¡å¼ï¼ˆä¸ä¼šå®é™…ä¿®æ”¹æ•°æ®ï¼‰");
    }

    // æ£€æŸ¥æºæ•°æ®åº“æ˜¯å¦å­˜åœ¨
    if !Path::new(&source_db_path).exists() {
        error!("âŒ æºæ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨: {}", source_db_path);
        return Ok(());
    }

    // æ‰§è¡Œè¿ç§»
    let result = migrate_data(&source_db_path, &target_db_path, dry_run).await;

    match result {
        Ok(data) => {
            info!("âœ… æ•°æ®è¿ç§»å®Œæˆï¼");
            info!("ğŸ“Š è¿ç§»ç»Ÿè®¡:");
            info!("  - Claudeä¾›åº”å•†: {} æ¡", data.claude_providers);
            info!("  - Codexä¾›åº”å•†: {} æ¡", data.codex_providers);
            info!("  - AgentæŒ‡å¯¼: {} æ¡", data.agent_guides);
            info!("  - MCPæœåŠ¡å™¨: {} æ¡", data.mcp_servers);
            info!("  - é€šç”¨é…ç½®: {} æ¡", data.common_configs);

            if !data.errors.is_empty() {
                warn!("âš ï¸  è¿ç§»è¿‡ç¨‹ä¸­é‡åˆ° {} ä¸ªé—®é¢˜:", data.errors.len());
                for error in &data.errors {
                    warn!("  - {}", error);
                }
            }

            if dry_run {
                info!("ğŸ” è¿™æ˜¯é¢„è§ˆæ¨¡å¼ï¼Œæ²¡æœ‰å®é™…ä¿®æ”¹æ•°æ®");
            }
        }
        Err(e) => {
            error!("âŒ è¿ç§»å¤±è´¥: {}", e);
        }
    }

    Ok(())
}

fn print_usage() {
    println!("ç”¨æ³•: migrate_data <æºæ•°æ®åº“è·¯å¾„> [ç›®æ ‡æ•°æ®åº“è·¯å¾„] [--dry-run]");
    println!();
    println!("ç¤ºä¾‹:");
    println!("  migrate_data ../ai-manager/ai_manager.db");
    println!("  migrate_data ../ai-manager/ai_manager.db data/new_ai_manager.db");
    println!("  migrate_data ../ai-manager/ai_manager.db --dry-run");
    println!();
    println!("å‚æ•°:");
    println!("  æºæ•°æ®åº“è·¯å¾„    - åŸPythonç‰ˆæœ¬çš„æ•°æ®åº“æ–‡ä»¶");
    println!("  ç›®æ ‡æ•°æ®åº“è·¯å¾„  - æ–°Rustç‰ˆæœ¬çš„æ•°æ®åº“æ–‡ä»¶ï¼ˆé»˜è®¤: data/ai_manager.dbï¼‰");
    println!("  --dry-run        - é¢„è§ˆæ¨¡å¼ï¼Œä¸å®é™…ä¿®æ”¹æ•°æ®");
}

async fn migrate_data(
    source_db_path: &str,
    target_db_path: &str,
    dry_run: bool,
) -> Result<MigratedData, Box<dyn std::error::Error>> {
    let mut migrated_data = MigratedData {
        claude_providers: 0,
        codex_providers: 0,
        agent_guides: 0,
        mcp_servers: 0,
        common_configs: 0,
        errors: Vec::new(),
    };

    // è¿æ¥æºæ•°æ®åº“
    info!("ğŸ“– è¿æ¥æºæ•°æ®åº“...");
    let source_pool = sqlx::SqlitePool::connect(&format!("sqlite:{}", source_db_path)).await?;
    info!("âœ… æºæ•°æ®åº“è¿æ¥æˆåŠŸ");

    // è¿æ¥ç›®æ ‡æ•°æ®åº“
    info!("ğŸ’¾ è¿æ¥ç›®æ ‡æ•°æ®åº“...");
    let target_db;
    if dry_run {
        info!("ğŸ” é¢„è§ˆæ¨¡å¼ï¼šè·³è¿‡ç›®æ ‡æ•°æ®åº“è¿æ¥");
        target_db = None;
    } else {
        // åˆ›å»ºç›®æ ‡æ•°æ®åº“ç›®å½•
        if let Some(parent) = Path::new(target_db_path).parent() {
            std::fs::create_dir_all(parent)?;
        }

        let target_config = migration_ai_manager_lib::DatabaseConfig {
            url: format!("sqlite:{}", target_db_path),
            max_connections: 10,
            min_connections: 1,
            connect_timeout: std::time::Duration::from_secs(30),
            idle_timeout: std::time::Duration::from_secs(600),
            max_lifetime: std::time::Duration::from_secs(1800),
        };

        let db = DatabaseManager::new(target_config).await?;
        info!("âœ… ç›®æ ‡æ•°æ®åº“è¿æ¥æˆåŠŸ");
        target_db = Some(db);
    }

    // è·å–åŠ å¯†å¯†é’¥ï¼ˆè¿™é‡Œä½¿ç”¨å›ºå®šçš„æµ‹è¯•å¯†é’¥ï¼Œå®é™…ä½¿ç”¨ä¸­åº”è¯¥ä».envè¯»å–ï¼‰
    let old_key = get_old_encryption_key();
    let new_key = get_new_encryption_key();

    let old_crypto = CryptoService::new(&old_key)?;
    let new_crypto = CryptoService::new(&new_key)?;

    info!("ğŸ” å¼€å§‹è¿ç§»æ•°æ®...");

    // è¿ç§»Claudeä¾›åº”å•†
    if let Some(ref db) = target_db {
        migrated_data.claude_providers =
            migrate_claude_providers(&source_pool, db, &old_crypto, &new_crypto, dry_run)
                .await
                .unwrap_or_else(|e| {
                    migrated_data.errors.push(format!("Claudeä¾›åº”å•†è¿ç§»å¤±è´¥: {}", e));
                    0
                });

        // è¿ç§»Codexä¾›åº”å•†
        migrated_data.codex_providers =
            migrate_codex_providers(&source_pool, db, &old_crypto, &new_crypto, dry_run)
                .await
                .unwrap_or_else(|e| {
                    migrated_data.errors.push(format!("Codexä¾›åº”å•†è¿ç§»å¤±è´¥: {}", e));
                    0
                });

        // è¿ç§»AgentæŒ‡å¯¼æ–‡ä»¶
        migrated_data.agent_guides =
            migrate_agent_guides(&source_pool, db, dry_run).await.unwrap_or_else(|e| {
                migrated_data.errors.push(format!("AgentæŒ‡å¯¼è¿ç§»å¤±è´¥: {}", e));
                0
            });

        // è¿ç§»MCPæœåŠ¡å™¨
        migrated_data.mcp_servers =
            migrate_mcp_servers(&source_pool, db, dry_run).await.unwrap_or_else(|e| {
                migrated_data.errors.push(format!("MCPæœåŠ¡å™¨è¿ç§»å¤±è´¥: {}", e));
                0
            });

        // è¿ç§»é€šç”¨é…ç½®
        migrated_data.common_configs =
            migrate_common_configs(&source_pool, db, dry_run).await.unwrap_or_else(|e| {
                migrated_data.errors.push(format!("é€šç”¨é…ç½®è¿ç§»å¤±è´¥: {}", e));
                0
            });
    } else {
        // é¢„è§ˆæ¨¡å¼ï¼Œåªè¯»å–æºæ•°æ®æ•°é‡
        migrated_data.claude_providers = sqlx::query("SELECT COUNT(*) FROM claude_providers")
            .fetch_one(&source_pool)
            .await?
            .get::<i64, _>(0) as usize;
        migrated_data.codex_providers = sqlx::query("SELECT COUNT(*) FROM codex_providers")
            .fetch_one(&source_pool)
            .await?
            .get::<i64, _>(0) as usize;
        migrated_data.agent_guides = sqlx::query("SELECT COUNT(*) FROM agent_guides")
            .fetch_one(&source_pool)
            .await?
            .get::<i64, _>(0) as usize;
        migrated_data.mcp_servers = sqlx::query("SELECT COUNT(*) FROM mcp_servers")
            .fetch_one(&source_pool)
            .await?
            .get::<i64, _>(0) as usize;
        migrated_data.common_configs = sqlx::query("SELECT COUNT(*) FROM common_configs")
            .fetch_one(&source_pool)
            .await?
            .get::<i64, _>(0) as usize;
    }

    Ok(migrated_data)
}

fn get_old_encryption_key() -> String {
    // å°è¯•ä»ç¯å¢ƒå˜é‡è·å–ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨æµ‹è¯•å¯†é’¥
    env::var("OLD_FERNET_KEY").unwrap_or_else(|_| {
        warn!("æœªæ‰¾åˆ°OLD_FERNET_KEYç¯å¢ƒå˜é‡ï¼Œä½¿ç”¨é»˜è®¤æµ‹è¯•å¯†é’¥");
        "dGVzdCBrZXkgZm9yIGZlcm5ldCB0ZXN0aW5nIHVuaXQgdGVzdHM=".to_string() // æµ‹è¯•å¯†é’¥
    })
}

fn get_new_encryption_key() -> String {
    // å°è¯•ä»ç¯å¢ƒå˜é‡è·å–ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨æµ‹è¯•å¯†é’¥
    env::var("FERNET_KEY").unwrap_or_else(|_| {
        warn!("æœªæ‰¾åˆ°FERNET_KEYç¯å¢ƒå˜é‡ï¼Œä½¿ç”¨é»˜è®¤æµ‹è¯•å¯†é’¥");
        "Jw4Ff1BWLnSykdfXDVOuEJCG6m9dyST5B1VhU_qg0fI=".to_string() // æµ‹è¯•å¯†é’¥
    })
}

async fn migrate_claude_providers(
    source_pool: &sqlx::SqlitePool,
    target_db: &DatabaseManager,
    old_crypto: &CryptoService,
    new_crypto: &CryptoService,
    dry_run: bool,
) -> Result<usize, Box<dyn std::error::Error>> {
    info!("ğŸ”„ è¿ç§»Claudeä¾›åº”å•†...");

    let rows = sqlx::query("SELECT * FROM claude_providers").fetch_all(source_pool).await?;

    info!("æ‰¾åˆ° {} ä¸ªClaudeä¾›åº”å•†", rows.len());

    let mut count = 0;
    for row in rows {
        let name: String = row.get("name");
        let _url: String = row.get("url");
        let encrypted_token: String = row.get("token");

        // è§£å¯†åŸå§‹token
        let token = match old_crypto.decrypt(&encrypted_token) {
            Ok(t) => t,
            Err(e) => {
                warn!("æ— æ³•è§£å¯†Claudeä¾›åº”å•† '{}' çš„token: {}ï¼Œè·³è¿‡", name, e);
                continue;
            }
        };

        // ç”¨æ–°å¯†é’¥åŠ å¯†token
        let new_encrypted_token = new_crypto.encrypt(&token)?;

        info!("  âœ… Claudeä¾›åº”å•†: {}", name);

        if !dry_run {
            // æ’å…¥åˆ°ç›®æ ‡æ•°æ®åº“
            sqlx::query(r#"
                INSERT INTO claude_providers (name, url, token, timeout, auto_update, type, enabled, opus_model, sonnet_model, haiku_model)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            "#)
            .bind(name.clone())
            .bind(row.get::<Option<String>, _>("url").unwrap_or_else(|| "https://api.anthropic.com".to_string()))
            .bind(new_encrypted_token)
            .bind(row.get::<Option<i64>, _>("timeout").unwrap_or(30000))
            .bind(row.get::<Option<i64>, _>("auto_update").unwrap_or(1))
            .bind(row.get::<Option<String>, _>("type").unwrap_or_else(|| "public_welfare".to_string()))
            .bind(row.get::<Option<i64>, _>("enabled").unwrap_or(0))
            .bind(row.get::<Option<String>, _>("opus_model"))
            .bind(row.get::<Option<String>, _>("sonnet_model"))
            .bind(row.get::<Option<String>, _>("haiku_model"))
            .execute(target_db.pool())
            .await?;
            count += 1;
        } else {
            count += 1;
        }
    }

    Ok(count)
}

async fn migrate_codex_providers(
    source_pool: &sqlx::SqlitePool,
    target_db: &DatabaseManager,
    old_crypto: &CryptoService,
    new_crypto: &CryptoService,
    dry_run: bool,
) -> Result<usize, Box<dyn std::error::Error>> {
    info!("ğŸ”„ è¿ç§»Codexä¾›åº”å•†...");

    let rows = sqlx::query("SELECT * FROM codex_providers").fetch_all(source_pool).await?;

    info!("æ‰¾åˆ° {} ä¸ªCodexä¾›åº”å•†", rows.len());

    let mut count = 0;
    for row in rows {
        let name: String = row.get("name");
        let encrypted_token: String = row.get("token");

        let token = match old_crypto.decrypt(&encrypted_token) {
            Ok(t) => t,
            Err(e) => {
                warn!("æ— æ³•è§£å¯†Codexä¾›åº”å•† '{}' çš„token: {}ï¼Œè·³è¿‡", name, e);
                continue;
            }
        };

        let new_encrypted_token = new_crypto.encrypt(&token)?;
        info!("  âœ… Codexä¾›åº”å•†: {}", name);

        if !dry_run {
            // æ’å…¥åˆ°ç›®æ ‡æ•°æ®åº“
            sqlx::query(
                r#"
                INSERT INTO codex_providers (name, url, token, type, enabled)
                VALUES (?, ?, ?, ?, ?)
            "#,
            )
            .bind(name.clone())
            .bind(
                row.get::<Option<String>, _>("url")
                    .unwrap_or_else(|| "https://api.openai.com".to_string()),
            )
            .bind(new_encrypted_token)
            .bind(
                row.get::<Option<String>, _>("type")
                    .unwrap_or_else(|| "public_welfare".to_string()),
            )
            .bind(row.get::<Option<i64>, _>("enabled").unwrap_or(0))
            .execute(target_db.pool())
            .await?;
            count += 1;
        } else {
            count += 1;
        }
    }

    Ok(count)
}

async fn migrate_agent_guides(
    source_pool: &sqlx::SqlitePool,
    target_db: &DatabaseManager,
    dry_run: bool,
) -> Result<usize, Box<dyn std::error::Error>> {
    info!("ğŸ”„ è¿ç§»AgentæŒ‡å¯¼æ–‡ä»¶...");

    let rows = sqlx::query("SELECT * FROM agent_guides").fetch_all(source_pool).await?;

    info!("æ‰¾åˆ° {} ä¸ªAgentæŒ‡å¯¼æ–‡ä»¶", rows.len());

    let mut count = 0;
    for row in rows {
        let name: String = row.get("name");
        let guide_type: String = row.get("type");
        let text: String = row.get("text");

        info!("  âœ… AgentæŒ‡å¯¼: {}", name);

        if !dry_run {
            // æ’å…¥åˆ°ç›®æ ‡æ•°æ®åº“
            sqlx::query(
                r#"
                INSERT INTO agent_guides (name, type, text)
                VALUES (?, ?, ?)
            "#,
            )
            .bind(name.clone())
            .bind(guide_type)
            .bind(text)
            .execute(target_db.pool())
            .await?;
            count += 1;
        } else {
            count += 1;
        }
    }

    Ok(count)
}

async fn migrate_mcp_servers(
    source_pool: &sqlx::SqlitePool,
    target_db: &DatabaseManager,
    dry_run: bool,
) -> Result<usize, Box<dyn std::error::Error>> {
    info!("ğŸ”„ è¿ç§»MCPæœåŠ¡å™¨...");

    let rows = sqlx::query("SELECT * FROM mcp_servers").fetch_all(source_pool).await?;

    info!("æ‰¾åˆ° {} ä¸ªMCPæœåŠ¡å™¨", rows.len());

    let mut count = 0;
    for row in rows {
        let name: String = row.get("name");
        let server_type: Option<String> = row.get("type");
        let timeout: Option<i64> = row.get("timeout");
        let command: String = row.get("command");
        let args: String = row.get("args");
        let env: Option<String> = row.get("env");

        info!("  âœ… MCPæœåŠ¡å™¨: {}", name);

        if !dry_run {
            // æ’å…¥åˆ°ç›®æ ‡æ•°æ®åº“
            sqlx::query(
                r#"
                INSERT INTO mcp_servers (name, type, timeout, command, args, env)
                VALUES (?, ?, ?, ?, ?, ?)
            "#,
            )
            .bind(name.clone())
            .bind(server_type)
            .bind(timeout.unwrap_or(30000))
            .bind(command)
            .bind(args)
            .bind(env)
            .execute(target_db.pool())
            .await?;
            count += 1;
        } else {
            count += 1;
        }
    }

    Ok(count)
}

async fn migrate_common_configs(
    source_pool: &sqlx::SqlitePool,
    target_db: &DatabaseManager,
    dry_run: bool,
) -> Result<usize, Box<dyn std::error::Error>> {
    info!("ğŸ”„ è¿ç§»é€šç”¨é…ç½®...");

    let rows = sqlx::query("SELECT * FROM common_configs").fetch_all(source_pool).await?;

    info!("æ‰¾åˆ° {} ä¸ªé€šç”¨é…ç½®", rows.len());

    let mut count = 0;
    for row in rows {
        let key: String = row.get("key");
        let value: String = row.get("value");
        let description: Option<String> = row.get("description");
        let category: Option<String> = row.get("category");
        let is_active: Option<i64> = row.get("is_active");

        info!("  âœ… é…ç½®é¡¹: {}", key);

        if !dry_run {
            // æ’å…¥åˆ°ç›®æ ‡æ•°æ®åº“
            sqlx::query(
                r#"
                INSERT INTO common_configs (key, value, description, category, is_active)
                VALUES (?, ?, ?, ?, ?)
            "#,
            )
            .bind(key.clone())
            .bind(value)
            .bind(description)
            .bind(category.unwrap_or_else(|| "general".to_string()))
            .bind(is_active.unwrap_or(1))
            .execute(target_db.pool())
            .await?;
            count += 1;
        } else {
            count += 1;
        }
    }

    Ok(count)
}
